{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext\n",
    "# ! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline tokenizer\n",
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())\n",
    "\n",
    "# other tokenizer\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "def tokenize_src(text):\n",
    "    return WordPunctTokenizer().tokenize(text.lower())[::-1]\n",
    "    #return WordPunctTokenizer().tokenize(text.lower())\n",
    "\n",
    "def tokenize_trg(text):\n",
    "    #return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "    return WordPunctTokenizer().tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_src,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize_trg,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9237\n",
      "Unique tokens in target (en) vocabulary: 6719\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'главного',\n",
       " 'чистые',\n",
       " 'ипподрома',\n",
       " 'украшен',\n",
       " 'atlanta',\n",
       " 'pegasus',\n",
       " 'факсимильными',\n",
       " 'духовки',\n",
       " 'тибр']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'breakfasts', 'groceries', 'earth', 'motorways', 'sella', 'mangga']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['located', 'in', 'messina', '’', 's', 'historic', 'centre', ',', 'grand', 'hotel', 'commercio', 'is', 'set', 'in', 'an', 'early', '19th', '-', 'century', 'building', ',', '500', 'metres', 'from', 'messina', 'station', '.'], 'src': ['.', 'мессины', 'вокзала', 'железнодорожного', 'от', 'метрах', '500', 'в', 'века', '19', 'начала', 'постройки', 'здании', 'в', 'мессины', 'города', 'центре', 'историческом', 'в', 'расположен', 'commercio', 'отель', '-', 'гранд']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in test_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in test_data.examples])\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "for word_seq in a:\n",
    "    print(word_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from routine import train_model\n",
    "\n",
    "\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "# for position encoding\n",
    "MAX_LENGTH_INPUT_SENTENCES = max(map(len, [vars(x)['src'] for x in dataset.examples]))\n",
    "MAX_LENGTH_OUTPUT_SENTENCES = max(map(len, [vars(x)['trg'] for x in dataset.examples]))\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "PAD_IDX = TRG.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.trg]:[torch.LongTensor of size 57x128]\n",
      "\t[.src]:[torch.LongTensor of size 44x128]\n",
      "torch.Size([44, 128]) torch.Size([57, 128])\n"
     ]
    }
   ],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")\n",
    "\n",
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMx2 LSTMx2 (Baseline model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,887,999 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import nmt_lstm\n",
    "\n",
    "encoder = nmt_lstm.Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = nmt_lstm.Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model_baseline = nmt_lstm.Seq2Seq(encoder, decoder, device).to(device)\n",
    "model_baseline.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model_baseline):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model_baseline.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=2)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMx2 LSTMx2 with Attention (Baseline model + Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,674,431 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import nmt_lstmAttention\n",
    "\n",
    "encoder_att = nmt_lstmAttention.Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder_att = nmt_lstmAttention.Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model_att = nmt_lstmAttention.Seq2Seq(encoder_att, decoder_att, device).to(device)\n",
    "model_att.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model_att):,} trainable parameters')\n",
    "\n",
    "optimizer_att = optim.Adam(model_att.parameters(), lr=1e-3)\n",
    "scheduler_att = ReduceLROnPlateau(optimizer_att, mode='min', factor=0.3, patience=2)\n",
    "criterion_att = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMx2 LSTMx2 with Attention and positional encoding (Baseline model + Attention + PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayer/LocalRepository/JupyterProjects/MADE_2019_nlp/03_NeuralMachineTranslation/nmt_lstmAttentionPE.py:129: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  self.word_pos = Variable(torch.from_numpy(np.stack((np.arange(n_position) for i in range(batch_size)),axis=0)).type(torch.LongTensor))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,720,767 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import nmt_lstmAttentionPE \n",
    "\n",
    "encoder_attpe = nmt_lstmAttentionPE.Encoder(INPUT_DIM, ENC_EMB_DIM, MAX_LENGTH_INPUT_SENTENCES, BATCH_SIZE, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder_attpe = nmt_lstmAttentionPE.Decoder(OUTPUT_DIM, DEC_EMB_DIM, MAX_LENGTH_OUTPUT_SENTENCES, BATCH_SIZE, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model_attpe = nmt_lstmAttentionPE.Seq2Seq(encoder_attpe, decoder_attpe, device).to(device)\n",
    "model_attpe.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model_attpe):,} trainable parameters')\n",
    "\n",
    "optimizer_attpe = optim.Adam(model_attpe.parameters(), lr=1e-3)\n",
    "scheduler_attpe = ReduceLROnPlateau(optimizer_attpe, mode='min', factor=0.3, patience=2)\n",
    "criterion_attpe = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nmt_cnnlstm\n",
    "\n",
    "#Encoder_cnn = nmt_cnnlstm.Encoder\n",
    "#Decoder_cnn = nmt_cnnlstm.Decoder\n",
    "#Seq2Seq_cnn = nmt_cnnlstm.Seq2Seq\n",
    "\n",
    "#enc_cnn = Encoder_cnn(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
    "#dec_cnn = Decoder_cnn(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "#model_cnn = Seq2Seq_cnn(enc_cnn, dec_cnn, device).to(device)\n",
    "\n",
    "#model_cnn.apply(init_weights)\n",
    "#print(f'The model has {count_parameters(model_cnn):,} trainable parameters')\n",
    "\n",
    "#PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "#optimizer_cnn = optim.Adam(model_cnn.parameters())\n",
    "#criterion_cnn = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14015"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = train_model(model, {\"train\":train_iterator,\"valid\":valid_iterator}, optimizer, criterion, scheduler, n_epochs=20,  clip=1, show_plots=True, nameModel=\"nmt_lstm.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_att = train_model(model_att, {\"train\":train_iterator,\"valid\":valid_iterator}, optimizer_att, criterion_att,scheduler_att, n_epochs=15,  clip=1, show_plots=True, nameModel=\"nmt_lstmAttention.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a47b4788ceff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_attpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_attpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_attpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_attpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_attpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_plots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnameModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nmt_lstmAttentionPE.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LocalRepository/JupyterProjects/MADE_2019_nlp/03_NeuralMachineTranslation/routine.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, iterators, optimizer, criterion, scheduler, n_epochs, clip, show_plots, nameModel)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_plots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LocalRepository/JupyterProjects/MADE_2019_nlp/03_NeuralMachineTranslation/routine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, show_plots, train_history, valid_history)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Let's clip the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_attpe = train_model(model_attpe, {\"train\":train_iterator,\"valid\":valid_iterator}, optimizer_attpe, criterion_attpe, scheduler_attpe, n_epochs=15,  clip=1, show_plots=True, nameModel=\"nmt_lstmAttentionPE.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cnn = train_model(model_cnn, {\"train\":train_iterator,\"valid\":valid_iterator}, optimizer_cnn, criterion_cnn, n_epochs=2,  clip=1, show_plots=True, nameModel=\"nmt_cnnlstm.pth\")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model (probability - for correct work need save and datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"4.548559629917145loss_nmt_lstm.pth_epoch11.pth\", \"rb\") as fp:\n",
    "#    best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "\n",
    "# because of rand split:train/valid/test, the different len(SRC.vocab)/len(TRG.vocab) obtain\n",
    "#INPUT_DIM = best_state_dict[\"encoder.embedding.weight\"].shape[0]\n",
    "#OUTPUT_DIM = best_state_dict[\"decoder.out.weight\"].shape[0]\n",
    "\n",
    "#Encoder = nmt_lstm.Encoder\n",
    "#Decoder = nmt_lstm.Decoder\n",
    "#Seq2Seq = nmt_lstm.Seq2Seq\n",
    "#enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "#dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "#model_load1 = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "#model_load1.load_state_dict(best_state_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Attention + PE\": model_attpe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del utils\n",
    "\n",
    "#import utils\n",
    "#import imp\n",
    "#imp.reload(utils)\n",
    "#generate_translation = utils.generate_translation\n",
    "#remove_tech_tokens = utils.remove_tech_tokens\n",
    "#get_text = utils.get_text\n",
    "#flatten = utils.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import tqdm\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n",
    "\n",
    "for name in models:\n",
    "    #test translate\n",
    "    print(\"MODEL:{}\\nEXAMPLE TRANSLATE:\\n\".format(name))\n",
    "    batch = next(iter(test_iterator))\n",
    "    for idx in [1,2]:\n",
    "        src = batch.src[:, idx:idx+1]\n",
    "        trg = batch.trg[:, idx:idx+1]\n",
    "        print(generate_translation(src, trg, models[name], TRG.vocab))\n",
    "        \n",
    "    original_text = []\n",
    "    generated_text = []\n",
    "    models[name].eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = models[name](src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output.argmax(dim=-1)\n",
    "\n",
    "            original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "            generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "    # original_text = flatten(original_text)\n",
    "    # generated_text = flatten(generated_text)\n",
    "    print(corpus_bleu([[text] for text in original_text], generated_text) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
