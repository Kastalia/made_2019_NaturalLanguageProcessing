{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "# ! pip  install subword-nmt\n",
    "# ! pip install nltk\n",
    "# ! pip install torchtext\n",
    "# ! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally. Downloading from github.\n",
      "File ‘data.txt’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline tokenizer\n",
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())\n",
    "\n",
    "# other tokenizer\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "def tokenize_src(text):\n",
    "    return WordPunctTokenizer().tokenize(text.lower())[::-1]\n",
    "    #return WordPunctTokenizer().tokenize(text.lower())\n",
    "\n",
    "def tokenize_trg(text):\n",
    "    #return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "    return WordPunctTokenizer().tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_src,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize_trg,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9279\n",
      "Unique tokens in target (en) vocabulary: 6769\n"
     ]
    }
   ],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)\n",
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'проходят',\n",
       " 'downtown',\n",
       " 'ин',\n",
       " 'guesthouse',\n",
       " 'художественной',\n",
       " 'ju',\n",
       " 'фуншала',\n",
       " 'джунглей',\n",
       " 'султан']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'packed', 'catania', 'canton', 'maris', 'slovenska', 'macba']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['they', 'are', 'all', 'equipped', 'with', 'a', 'fan', ',', 'while', 'the', 'kitchen', 'comes', 'with', 'a', 'fridge', 'and', 'stove', '.'], 'src': ['.', 'плитой', 'и', 'холодильником', 'оснащена', 'кухня', '.', 'вентилятором', 'воспользоваться', 'могут', 'гости']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAEICAYAAAByPazKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3df5gdVZ3n8ffHIOGHQgJpMOSHHTAwBp8xYAtxUBeJGhJcg7uwJjoSmLhRN7i66Eii8ww8ambDLAryiHEiZEJmhBhBhqxGMaLI+oz8SBADIUSaEEgnMWl+6ogGE777R51Lis7t7pvcX119P6/nuc+tOnWq7qnue+636tSpU4oIzMzMbOB7VbMLYGZmZpVx0DYzMysIB20zM7OCcNA2MzMrCAdtMzOzgnDQNjMzKwgHbauapM2S3t2Ez22XFJIOavRnmzWapKWSvlzF+v8h6fhalilt1/W/gRy0rTCa9eNgVlKU76CkOyV9NJ8WEa+JiE3NKlO1ivK3rzcH7RYlaUizy2A22LTaWZ81noP2ACTpUklbJf1e0kZJk1P6UElXS9qWXldLGpqWXSjpFz22E5LekKaXSlokaZWkPwDvknSopK9IekLS85J+IenQlH+SpH+X9JykX0s6s8Kyv0rSPEmPSXpa0gpJR6VlpeasWZKelPSUpC/k1j1U0g2SnpW0QdLnJHWlZf8CjAX+b2rm+1zuYz9cbntmtVTuO5j7Ts+W9CTw05T3u5J+m+rVXZJOzm1nqaRrJf0g1fF7JJ2QlknSVZJ2pnXXSXpTmbIMl/R9Sd2pvnxf0ui0bAHwDuDrqZxfT+n534MjJS1L6z8h6e8kvSotuzD9FlyZtv24pKkV/o1c/+stIvwaQC/gJGALcFyabwdOSNNfBO4GjgHagH8HvpSWXQj8ose2AnhDml4KPA+cQXawdghwLXAnMAoYAvwVMDTNPw1MS3nfk+bbeinzZuDdafrTqYyj07b+Cbgpty8BfAs4FHgzsAt4Y1q+EPg5MDytvw7oKvc5lWzPL79q/erjO7gMOBw4NKX/DfDaVAeuBh7IrbMUeAY4DTgI+DawPC2bAqwFhgEC3giMzK335TR9NPBfgcPS53wX+LfcZ9wJfLRH2fO/B8uA29K67cBvgNlp2YXAn4H/nn4XPgFsA9Tf38T1vwHfwWYXwK8e/xB4A7ATeDfw6h7LHgOm5eanAJvT9IX0H7SX5Za9Cvgj8OYyZbgU+JceabcDs3opc77SbgAm55aNTD8AB+Uq2ejc8nuBGWl6EzAlt+yjFVbastvzy69av/r4Dh7fxzrDUp4j0/xS4Lrc8mnAI2n6LLIAOgl4VY/tLCUF7TKfMRF4Njd/J70EbbJAvAuYkFv2MeDONH0h0Jlbdlha93X9/U1c/+v/cvP4ABMRnWRHq5cDOyUtl3RcWnwc8EQu+xMprVJbctMjyM62HyuT7/XA+alp/DlJzwFvJ6uA/Xk9cGtuvQ3AHuDYXJ7f5qZfAF6Tpo/rUcb8dF96255Zo7z8XZU0RNLC1ET8O7JgA1mdKyn7nY2InwJfJ2sF2yFpsaQjen6YpMMk/VNq2v4dcBcwTJX1VRkBHMy+vyWjypUvIl5Ik5XUK9f/OnPQHoAi4saIeDtZBQjgirRoW0orGZvSAP5AdkQMgKTXldt0bvop4E/ACWXybSE70x6Wex0eEQsrKP4WYGqPdQ+JiK0VrLudrFmsZEwf5Tdrht6+g/n0DwHTyVrLjiQ7I4Ssubv/D4i4JiLeApwMnAj8bZlsnyG7lHZ6RBwBvLPHZ/RVV54iO/vt+VtSSR3tj+t/nTloDzCSTpJ0lrIOZn8ia8LekxbfBPydpDZJI4C/B/41Lfs1cLKkiZIOITtT71VEvAQsAb4q6bh0dvC29Ln/CvxnSVNS+iGSzix1dOnHN4EFkl6f9qdN0vQKd38FMD91shkFXNxj+Q6g5veZmu2HSr6DryVrfn6a7ED6HyrduKS3Sjpd0qvJDsT/xN763/Mz/gg8lzp6XVZpOSNiD1ldWyDptamuXsLe35JquP7XmYP2wDOUrEPGU2TNPscAn0/LvgysIeug8SBwf0ojIn5D1lHtJ8CjwCt6kvfis2k795F1jLmC7DraFrIzhc8D3WRHz39LZd+XrwErgR9L+j1Zp5TTK1iPVP4u4PG0HzeT/fiV/G+yg5bnJH22wm2a1VIl38FlZM3NW4GHyepApY4g61j1bNrG08CVZfJdTdb56qm0/R/1WP414LzUE/uaMut/kuygYBPZb8WNZAfx1XL9rzOli/dmA46kT5B1KvlPzS6LmTWW6395PtO2AUPSSElnpHs9TyK7bndrs8tlZvXn+l8Zj95jA8nBZPd1jgOeA5YD32hqicysUVz/K+DmcTMzs4Jw87iZmVlBDPjm8REjRkR7e3uzi2E2oK1du/apiGhrdjn64rpsVpm+6vOAD9rt7e2sWbOm2cUwG9AkPdF/ruZyXTarTF/12c3jZmZmBeGgbWZmVhAO2mZmZgXhoG1mZlYQDtpmZmYF4aBtZmZWEA7aZmZmBeGgbWZmVhAO2mZmZgUx4EdEa6T2eT/oN8/mhec0oCRm1giu81Y0PtM2MzMrCAdtMzOzgnDQNjMzK4h+g7akJZJ2Snool/YdSQ+k12ZJD6T0dkl/zC37Zm6dt0h6UFKnpGskqT67ZGZmNjhVcqa9FDg7nxARH4yIiRExEbgF+F5u8WOlZRHx8Vz6ImAOMD69XrFNM6u/cgfhKf2TkjZKWi/pH3Pp89OB9kZJU3LpZ6e0TknzGrkPZq2s36AdEXcBz5Rbls6W/xtwU1/bkDQSOCIifhkRASwDzt3/4ppZlZbS44BZ0ruA6cBfRsTJwJUpfQIwAzg5rfMNSUMkDQGuBaYCE4CZKa+Z1Vm117TfAeyIiEdzaeMk/UrSzyW9I6WNArpyebpSWlmS5khaI2lNd3d3lUU0s5JeDsI/ASyMiF0pz86UPh1YHhG7IuJxoBM4Lb06I2JTRLwILE95zazOqg3aM3nlWfZ2YGxEnAJcAtwo6Qig3PXr6G2jEbE4IjoioqOtra3KIppZP04E3iHpnnSw/daUPgrYkstXOtjuLd3M6uyAB1eRdBDwX4C3lNLSkXrpaH2tpMfIfhC6gNG51UcD2w70s82spg4ChgOTgLcCKyQdT+8H2+UO9ssehEuaQ9aXhbFjx9aksGatrJoz7XcDj0TEy83ektrS9S5SpR8PbIqI7cDvJU1K18EvAG6r4rPNrHa6gO9F5l7gJWBESh+Ty1c62O4tfR9uNTOrrUpu+boJ+CVwkqQuSbPTohns2wHtncA6Sb8GbgY+HhGl62efAK4juy72GPDDGpTfzKr3b8BZAJJOBA4GngJWAjMkDZU0juwg/F7gPmC8pHGSDib7LVjZlJKbtZh+m8cjYmYv6ReWSbuF7BawcvnXAG/az/KZWQ2lg/AzgRGSuoDLgCXAknQb2IvArHSXx3pJK4CHgd3A3IjYk7ZzMXA7MARYEhHrG74zZi3IDwwxayG9HYQDf91L/gXAgjLpq4BVNSyamVXAw5iamZkVhIO2mZlZQThom5mZFYSDtpmZWUE4aJuZmRWEg7aZmVlBOGibmZkVhIO2mZlZQThom5mZFYSDtpmZWUE4aJuZmRWEg7aZmVlBOGibmZkVhIO2mZlZQThom5mZFYSDtpmZWUE4aJu1EElLJO2U9FCZZZ+VFJJGpHlJukZSp6R1kk7N5Z0l6dH0mtXIfTBrZQ7aZq1lKXB2z0RJY4D3AE/mkqcC49NrDrAo5T0KuAw4HTgNuEzS8LqW2syACoJ2uSNzSZdL2irpgfSalls2Px2Zb5Q0JZd+dkrrlDSv9rtiZv2JiLuAZ8osugr4HBC5tOnAssjcDQyTNBKYAqyOiGci4llgNWUOBMys9io5015K+Qp5VURMTK9VAJImADOAk9M635A0RNIQ4FqyI/cJwMyU18yaTNL7ga0R8esei0YBW3LzXSmtt/Ry254jaY2kNd3d3TUstVlr6jdo93FkXs50YHlE7IqIx4FOsuaz04DOiNgUES8Cy1NeM2siSYcBXwD+vtziMmnRR/q+iRGLI6IjIjra2toOvKBmBlR3Tfvi1DllSe56VtVH5mbWUCcA44BfS9oMjAbul/Q6sno6Jpd3NLCtj3Qzq7MDDdqLyCr7RGA78JWUXvWRObhJzaxRIuLBiDgmItojop0sIJ8aEb8FVgIXpF7kk4DnI2I7cDvwXknD0wH7e1OamdXZAQXtiNgREXsi4iXgW2TN31CjI3M3qZnVh6SbgF8CJ0nqkjS7j+yrgE1kl7m+BfwPgIh4BvgScF96fTGlmVmdHXQgK0kamY64AT4AlHqWrwRulPRV4DiyW0XuJTvTHi9pHLCVrLPah6opuJntv4iY2c/y9tx0AHN7ybcEWFLTwplZv/oN2unI/ExghKQusvszz5Q0kayJezPwMYCIWC9pBfAwsBuYGxF70nYuJmtCGwIsiYj1Nd8bMzOzQazfoN3Lkfn1feRfACwok76KrLnNzMzMDoBHRDMzMysIB20zM7OCcNA2MzMrCAdtMzOzgnDQNjMzKwgHbTMzs4Jw0DYzMysIB20zM7OCcNA2MzMrCAdtMzOzgjigB4aYmQ107fN+0OwimNWcz7TNzMwKwkHbzMysIBy0zczMCsJB26yFSFoiaaekh3Jp/0fSI5LWSbpV0rDcsvmSOiVtlDQll352SuuUNK/R+2HWqhy0zVrLUuDsHmmrgTdFxF8CvwHmA0iaAMwATk7rfEPSEElDgGuBqcAEYGbKa2Z15qBt1kIi4i7gmR5pP46I3Wn2bmB0mp4OLI+IXRHxONAJnJZenRGxKSJeBJanvGZWZw7aZpb3N8AP0/QoYEtuWVdK6y19H5LmSFojaU13d3cdimvWWhy0zQwASV8AdgPfLiWVyRZ9pO+bGLE4IjoioqOtra02BTVrYR5cxcyQNAt4HzA5IkoBuAsYk8s2GtiWpntLN7M66vdMe396m0pql/RHSQ+k1zdz67xF0oOpt+k1ksodrZtZg0k6G7gUeH9EvJBbtBKYIWmopHHAeOBe4D5gvKRxkg4m66y2stHlNmtFlZxpLwW+DizLpa0G5kfEbklXkPU2vTQteywiJpbZziJgDllHl1VkvVF/WCbfoFDJEIqbF57TgJKY7SXpJuBMYISkLuAysvo7FFidjqXvjoiPR8R6SSuAh8mazedGxJ60nYuB24EhwJKIWN/wnTFrQf0G7Yi4S1J7j7Qf52bvBs7raxuSRgJHRMQv0/wy4FwGcdA2G4giYmaZ5Ov7yL8AWFAmfRXZwbeZNVAtOqLle5sCjJP0K0k/l/SOlDaK7PpYSa+9TcE9Ts3MzMqpKmiX6W26HRgbEacAlwA3SjqC/ehtCu5xamZmVs4B9x4v19s0InYBu9L0WkmPASeSnVmPzq3u3qZmZmb76YDOtHvrbSqpLQ1xiKTjyXqbboqI7cDvJU1KvcYvAG6ruvRmZmYtpN8z7f3pbQq8E/iipN3AHuDjEVEaMvETZD3RDyW7Bu5OaGZmZvuhkt7jFfc2jYhbgFt6WbYGeNN+lc7MzMxe5mFMzczMCsLDmJqZVamSwZTAAypZ9XymbWZmVhAO2mZmZgXhoG1mZlYQDtpmZmYF0TId0SrtKGJmZjZQ+UzbzMysIBy0zczMCqJlmsdrxc3sZmbWLD7TNmshkpZI2inpoVzaUZJWS3o0vQ9P6ZJ0jaROSesknZpbZ1bK/2h64p+ZNYCDtllrWQqc3SNtHnBHRIwH7kjzAFPJntQ3HpgDLIIsyJM9OOh04DTgslKgN7P6cvO4WQuJiLsktfdInk72JD+AG4A7yR69Ox1YFhEB3C1pmKSRKe/q0hP8JK0mOxC4qc7FbwpfErOBxGfaZnZseuY96f2YlD4K2JLL15XSekvfh6Q5ktZIWtPd3V3zgpu1GgdtM+uNyqRFH+n7JkYsjoiOiOhoa2uraeHMWpGDtpntSM3epPedKb0LGJPLNxrY1ke6mdWZg7aZrQRKPcBnAbfl0i9IvcgnAc+n5vPbgfdKGp46oL03pZlZnbkjmlkLkXQTWUeyEZK6yHqBLwRWSJoNPAmcn7KvAqYBncALwEUAEfGMpC8B96V8Xyx1SjOz+nLQNmshETGzl0WTy+QNYG4v21kCLKlh0cysAhU1j3tABjMzs+ar9Jr2Ujwgg5mZWVNVFLQj4i6g5zWr6WQDMZDez82lL4vM3UBpQIYppAEZIuJZoDQgg5mZmVWgmt7jdRuQwczMzPZVj1u+qh6QwaMomZmZ7auaoF23ARk8ipKZmdm+qgnaHpDBzMysgSq6T9sDMpiZmTVfRUHbAzKYmZk1n0dEM7PC8TOurVX5gSFmZmYF4aBtZmZWEA7aZmZmBeGgbWZmVhAO2mZmZgXhoG1mAEj6X5LWS3pI0k2SDpE0TtI96XG635F0cMo7NM13puXtzS29WWtw0DYzJI0C/ifQERFvAoYAM4ArgKvSI3ifBWanVWYDz0bEG4CrUj4zqzPfp91EldxrunnhOQ0oiRmQ/R4cKunPwGHAduAs4ENp+Q3A5cAiskfwXp7Sbwa+LklpcCUzqxOfaZsZEbEVuJJsSOLtwPPAWuC5iNidsuUfp/vyo3bT8ueBoxtZZrNW5KBtZqSH+EwHxgHHAYcDU8tkLZ1JV/SoXT9m16y2HLTNDODdwOMR0R0Rfwa+B/wVMExS6TJa/nG6Lz9qNy0/EtjnAUB+zK5ZbTlomxlkzeKTJB0mSWQPA3oY+BlwXsrT8xG8pUfzngf81NezzerPQdvMiIh7yDqU3Q88SPbbsBi4FLhEUifZNevr0yrXA0en9EuAeQ0vtFkLcu9xMwMgIi4DLuuRvAk4rUzePwHnN6JcZraXz7TNzMwKwkHbzMysIBy0zczMCsJB28zMrCActM3MzArigIO2pJMkPZB7/U7SpyVdLmlrLn1abp356alAGyVNqc0umJmZtYYDvuUrIjYCEwEkDQG2ArcCF5E9FejKfH5JE8ieGnQy2TCJP5F0YkTsOdAymJkViR8SZNWqVfP4ZOCxiHiijzzTgeURsSsiHgc6KXP/p5mZmZVXq6A9A7gpN3+xpHWSlqQHEUDuqUBJ/olBr+CHDJiZme2r6qAt6WDg/cB3U9Ii4ASypvPtwFdKWcusXnasYj9kwMzMbF+1ONOeCtwfETsAImJHROyJiJeAb7G3CfzlpwIl+ScGmZmZWT9qEbRnkmsalzQyt+wDwENpeiUwQ9JQSeOA8cC9Nfh8MzOzllDVA0MkHQa8B/hYLvkfJU0ka/reXFoWEeslrSB73N9uYK57jpuZmVWuqqAdES+QPa4vn/aRPvIvABZU85lmZmatyiOimZmZFYSDtpmZWUE4aJsZAJKGSbpZ0iOSNkh6m6SjJK2W9Gh6H57yStI1aVjidZJObXb5zVqBg7aZlXwN+FFE/AXwZmADMA+4IyLGA3ekechu9RyfXnPIxmcwszpz0DYzJB0BvBO4HiAiXoyI58iGH74hZbsBODdNTweWReZuYFiP2z3NrA4ctM0M4HigG/hnSb+SdJ2kw4FjI2I7QHo/JuWvaFhiD0lsVlsO2mYG2e2fpwKLIuIU4A/sbQovp6JhiT0ksVltOWibGWRnyl0RcU+av5ksiO8oNXun9525/B6W2KzBHLTNjIj4LbBF0kkpaTLZ6IUrgVkpbRZwW5peCVyQepFPAp4vNaObWf1UNSKamQ0qnwS+nZ7ctwm4iOzAfoWk2cCTwPkp7ypgGtAJvJDymlmdOWibGQAR8QDQUWbR5DJ5A5hb90KZ2Su4edzMzKwgHLTNzMwKwkHbzMysIBy0zczMCsJB28zMrCActM3MzArCQdvMzKwgfJ/2ANc+7wf95tm88JwGlMTMzJrNZ9pmZmYFUXXQlrRZ0oOSHpC0JqUdJWm1pEfT+/CULknXSOqUtE7SqdV+vpmZWauo1Zn2uyJiYkSUhkCcB9wREeOBO9j7iL+pwPj0mgMsqtHnm5mZDXr1ah6fDtyQpm8Azs2lL4vM3cCw0mP/zMzMrG+1CNoB/FjSWklzUtqxpcf0pfdjUvooYEtu3a6U9gqS5khaI2lNd3d3DYpoZmZWfLXoPX5GRGyTdAywWtIjfeRVmbTYJyFiMbAYoKOjY5/lZmZmrajqM+2I2JbedwK3AqcBO0rN3ul9Z8reBYzJrT4a2FZtGczMzFpBVUFb0uGSXluaBt4LPASsBGalbLOA29L0SuCC1It8EvB8qRndzMzM+lZt8/ixwK2SStu6MSJ+JOk+YIWk2cCTwPkp/ypgGtAJvABcVOXnm1kNSRoCrAG2RsT7JI0DlgNHAfcDH4mIFyUNBZYBbwGeBj4YEZubVGyzllFV0I6ITcCby6Q/DUwukx7A3Go+08zq6lPABuCINH8FcFVELJf0TWA22a2as4FnI+INkmakfB9sRoHNWolHRDMzACSNBs4BrkvzAs4Cbk5Zet6+Wbqt82ZgcspvZnXkoG1mJVcDnwNeSvNHA89FxO40n79F8+XbN9Py51P+V/Dtm2a15aBtZkh6H7AzItbmk8tkjQqW7U2IWBwRHRHR0dbWVoOSmrU2P+XLzADOAN4vaRpwCNk17avJRi08KJ1N52/RLN2+2SXpIOBI4JnGF9ustfhM28yIiPkRMToi2oEZwE8j4sPAz4DzUraet2+Wbus8L+X3QEhmdeagbWZ9uRS4RFIn2TXr61P69cDRKf0S9j4UyMzqyM3jZvYKEXEncGea3kQ2ymHPPH9i7/gLZtYgPtM2MzMrCAdtMzOzgnDQNjMzKwgHbTMzs4Jw0DYzMysIB20zM7OCcNA2MzMrCN+nbWY2gLTP+0G/eTYvPKcBJbGByGfaZmZmBeGgbWZmVhAO2mZmZgXha9pmZgXj696t64DPtCWNkfQzSRskrZf0qZR+uaStkh5Ir2m5deZL6pS0UdKUWuyAmZlZq6jmTHs38JmIuF/Sa4G1klanZVdFxJX5zJImkD2n92TgOOAnkk6MiD1VlMHMzKxlHPCZdkRsj4j70/TvgQ3AqD5WmQ4sj4hdEfE40EmZR/6ZmZlZeTXpiCapHTgFuCclXSxpnaQlkoantFHAltxqXfQS5CXNkbRG0pru7u5aFNHMzKzwqg7akl4D3AJ8OiJ+BywCTgAmAtuBr5Syllk9ym0zIhZHREdEdLS1tVVbRDPrRx99VI6StFrSo+l9eEqXpGtSH5V1kk5t7h6YtYaqgrakV5MF7G9HxPcAImJHROyJiJeAb7G3CbwLGJNbfTSwrZrPN7OaKfVReSMwCZib+qHMA+6IiPHAHWkeYCowPr3mkB2sm1mdVdN7XMD1wIaI+GoufWQu2weAh9L0SmCGpKGSxpFV9nsP9PPNrHb66KMyHbghZbsBODdNTweWReZuYFiPum9mdVBN7/EzgI8AD0p6IKV9HpgpaSJZ0/dm4GMAEbFe0grgYbKj+rnuOV4bldyzCb5v0yrTo4/KsRGxHbLALumYlK23Pirbe2xrDtmZOGPHjq1ruc1awQEH7Yj4BeWvU6/qY50FwIID/UyrjgdksP707KOSNaiVz1ombZ8+KhGxGFgM0NHRUbYPi5lVzsOYmhlQvo8KsKPU7J3ed6Z091ExawIHbTPrtY8KWV+UWWl6FnBbLv2C1It8EvB8qRndzOrHY4+bGfTeR2UhsELSbOBJ4Py0bBUwjWyQpBeAixpbXLPW5KBtZn31UQGYXCZ/AHPrWigz24ebx83MzArCQdvMzKwgHLTNzMwKwte0zcwGIQ+6NDj5TNvMzKwgHLTNzMwKws3j9goe6tTMbODymbaZmVlBOGibmZkVhJvHbb+5Cd1s8HB9LhafaZuZmRWEg7aZmVlBOGibmZkVhK9pm5lZn3zde+AYFEG70uH6zMzMiszN42ZmZgXR8DNtSWcDXwOGANdFxMJGl8Hqz81pg5/rsuW5zjdGQ4O2pCHAtcB7gC7gPkkrI+LhRpbDBgY/hai46lWXfalrcHNgr16jz7RPAzojYhOApOXAdMBB23pVq4ruH4yacl22umj0gVvR6nyjg/YoYEtuvgs4vWcmSXOAOWn2PyRtLLOtEcBTNS9h4w2G/Wj6PuiKqjcxAniqBttpltc3+PNqWZdhAHyHasj7MjCV3ZcBWud7rc+NDtoqkxb7JEQsBhb3uSFpTUR01KpgzTIY9sP70JJqVpdhcP39vS8D02DZl0b3Hu8CxuTmRwPbGlwGM6ue67JZEzQ6aN8HjJc0TtLBwAxgZYPLYGbVc102a4KGNo9HxG5JFwO3k90msiQi1h/g5vptciuIwbAf3ocWU+O6DIPr7+99GZgGxb4oYp/LUGZmZjYAeUQ0MzOzgnDQNjMzK4hCBm1JZ0vaKKlT0rxml6cSksZI+pmkDZLWS/pUSj9K0mpJj6b34c0ua38kDZH0K0nfT/PjJN2T9uE7qWPSgCVpmKSbJT2S/h9vK+L/YTAoYl0uGUx1uqTodTtvsNbzwgXt3PCJU4EJwExJE5pbqorsBj4TEW8EJgFzU7nnAXdExHjgjjQ/0H0K2JCbvwK4Ku3Ds8DsppSqcl8DfhQRfwG8mWxfivh/KLQC1+WSwVSnS4pet/MGZz2PiEK9gLcBt+fm5wPzm12uA9iP28jGbd4IjExpI4GNzS5bP+UeTfZlPwv4PtkgG08BB5X7/wy0F3AE8DipE2YuvVD/h8HwGix1OVf+QtbpXPkLXbd77MugreeFO9Om/PCJo5pUlgMiqR04BbgHODYitgOk92OaV7KKXA18DngpzR8NPBcRu9P8QP9/HA90A/+cmgGvk3Q4xfs/DAaFr8slBa/TJUWv23mDtp4XMWhXNHziQCXpNcAtwKcj4nfNLs/+kPQ+YGdErM0nl8k6kP8fBwGnAosi4hTgDxSxiWxwKNp3p6wi1+mSQVK38wZtPS9i0C7s8ImSXk1Wub8dEd9LyTskjUzLRwI7m1W+CpwBvF/SZmA5WTPa1cAwSaWBegb6/6ML6IqIe9L8zWSVu0j/h8GisHW5ZBDU6ZLBULfzBm09L2LQLuTwiZIEXA9siIiv5hatBGal6Vlk18UGpIiYHxGjIzT299oAAADYSURBVKKd7O/+04j4MPAz4LyUbaDvw2+BLZJOSkmTyR4nWZj/wyBSyLpcMhjqdMlgqNt5g7meF3JENEnTyI4CS8MnLmhykfol6e3A/wMeZO81o8+TXQNbAYwFngTOj4hnmlLI/SDpTOCzEfE+SceTHZ0fBfwK+OuI2NXM8vVF0kTgOuBgYBNwEdkBbOH+D0VXxLpcMtjqdEmR63beYK3nhQzaZmZmraiIzeNmZmYtyUHbzMysIBy0zczMCsJB28zMrCActM3MzArCQdvMzKwgHLTNzMwK4v8DEtFrgQmNgWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in test_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in test_data.examples])\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from routine import train_model\n",
    "\n",
    "\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "PAD_IDX = TRG.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.trg]:[torch.LongTensor of size 58x128]\n",
      "\t[.src]:[torch.LongTensor of size 60x128]\n",
      "torch.Size([60, 128]) torch.Size([58, 128])\n"
     ]
    }
   ],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")\n",
    "\n",
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,937,201 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import nmt_lstm\n",
    "\n",
    "encoder = nmt_lstm.Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = nmt_lstm.Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model_baseline = nmt_lstm.Seq2Seq(encoder, decoder, device).to(device)\n",
    "model_baseline.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model_baseline):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model_baseline.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=2)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,723,633 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import nmt_lstmAttention\n",
    "\n",
    "encoder_att = nmt_lstmAttention.Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder_att = nmt_lstmAttention.Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model_att = nmt_lstmAttention.Seq2Seq(encoder_att, decoder_att, device).to(device)\n",
    "model_att.apply(init_weights)\n",
    "\n",
    "print(f'The model has {count_parameters(model_att):,} trainable parameters')\n",
    "\n",
    "optimizer_att = optim.Adam(model_att.parameters(), lr=1e-3)\n",
    "scheduler_att = ReduceLROnPlateau(optimizer_att, mode='min', factor=0.3, patience=2)\n",
    "criterion_att = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nmt_cnnlstm\n",
    "\n",
    "#Encoder_cnn = nmt_cnnlstm.Encoder\n",
    "#Decoder_cnn = nmt_cnnlstm.Decoder\n",
    "#Seq2Seq_cnn = nmt_cnnlstm.Seq2Seq\n",
    "\n",
    "#enc_cnn = Encoder_cnn(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
    "#dec_cnn = Decoder_cnn(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "#model_cnn = Seq2Seq_cnn(enc_cnn, dec_cnn, device).to(device)\n",
    "\n",
    "#model_cnn.apply(init_weights)\n",
    "#print(f'The model has {count_parameters(model_cnn):,} trainable parameters')\n",
    "\n",
    "#PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "#optimizer_cnn = optim.Adam(model_cnn.parameters())\n",
    "#criterion_cnn = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = train_model(model, {\"train\":train_iterator,\"valid\":valid_iterator}, optimizer, criterion, scheduler, n_epochs=20,  clip=1, show_plots=True, nameModel=\"nmt_lstm.pth\")\n",
    "if device==torch.device('cuda'):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [   4,    4,    4,  ...,    4,    4,    4],\n",
      "        [ 194, 1302, 9007,  ...,  265,  487,    0],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]])\n",
      "torch.Size([42, 128])\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a233678bf3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_att\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler_att\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_plots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnameModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nmt_lstmAttention.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LocalRepository/JupyterProjects/MADE_2019_nlp/03_NeuralMachineTranslation/routine.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, iterators, optimizer, criterion, scheduler, n_epochs, clip, show_plots, nameModel)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0msince\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_plots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/LocalRepository/JupyterProjects/MADE_2019_nlp/03_NeuralMachineTranslation/routine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, show_plots, train_history, valid_history)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Let's clip the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/packages/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_att = train_model(model_att, {\"train\":train_iterator,\"valid\":valid_iterator}, optimizer_att, criterion_att,scheduler_att, n_epochs=15,  clip=1, show_plots=True, nameModel=\"nmt_lstmAttention.pth\")\n",
    "if device==torch.device('cuda'):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_cnn = train_model(model_cnn, {\"train\":train_iterator,\"valid\":valid_iterator}, optimizer_cnn, criterion_cnn, n_epochs=2,  clip=1, show_plots=True, nameModel=\"nmt_cnnlstm.pth\")\n",
    "if device==torch.device('cuda'):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"4.548559629917145loss_nmt_lstm.pth_epoch11.pth\", \"rb\") as fp:\n",
    "    best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "\n",
    "# because of rand split:train/valid/test, the different len(SRC.vocab)/len(TRG.vocab) obtain\n",
    "INPUT_DIM = best_state_dict[\"encoder.embedding.weight\"].shape[0]\n",
    "OUTPUT_DIM = best_state_dict[\"decoder.out.weight\"].shape[0]\n",
    "\n",
    "Encoder = nmt_lstm.Encoder\n",
    "Decoder = nmt_lstm.Decoder\n",
    "Seq2Seq = nmt_lstm.Seq2Seq\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "model_load1 = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "model_load1.load_state_dict(best_state_dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load model 2 (attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"4.506073224544525loss_nmt_lstmAttention.pth_epoch13.pth\", \"rb\") as fp:\n",
    "    best_state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "\n",
    "# because of rand split:train/valid/test, the different len(SRC.vocab)/len(TRG.vocab) obtain\n",
    "INPUT_DIM = best_state_dict[\"encoder.embedding.weight\"].shape[0]\n",
    "OUTPUT_DIM = best_state_dict[\"decoder.out.weight\"].shape[0]\n",
    "\n",
    "Encoder = nmt_lstmAttention.Encoder\n",
    "Decoder = nmt_lstmAttention.Decoder\n",
    "Seq2Seq = nmt_lstmAttention.Seq2Seq\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "model_load2 = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "model_load2.load_state_dict(best_state_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"load model1\":model_load1,\"load model2\":model_load2,\"baseline model\": model,\"attention model\": model_att}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del utils\n",
    "\n",
    "#import utils\n",
    "#import imp\n",
    "#imp.reload(utils)\n",
    "#generate_translation = utils.generate_translation\n",
    "#remove_tech_tokens = utils.remove_tech_tokens\n",
    "#get_text = utils.get_text\n",
    "#flatten = utils.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "import tqdm\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100\n",
    "\n",
    "for name in models:\n",
    "    #test translate\n",
    "    print(\"MODEL:{}\\nEXAMPLE TRANSLATE:\\n\".format(name))\n",
    "    batch = next(iter(test_iterator))\n",
    "    for idx in [1,2]:\n",
    "        src = batch.src[:, idx:idx+1]\n",
    "        trg = batch.trg[:, idx:idx+1]\n",
    "        print(generate_translation(src, trg, models[name], TRG.vocab))\n",
    "        \n",
    "    original_text = []\n",
    "    generated_text = []\n",
    "    models[name].eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = models[name](src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output.argmax(dim=-1)\n",
    "\n",
    "            original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "            generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "    # original_text = flatten(original_text)\n",
    "    # generated_text = flatten(generated_text)\n",
    "    print(corpus_bleu([[text] for text in original_text], generated_text) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
